When I began studying robotics in college, I was introduced and taught from your standard textbooks: the Thrun book, the Bishop book, the Russell/Norvig book, etc. Never did I think it would cripple my perspective so much. Modern education in robotics begins with machine learning, planning, and estimation these days. Lost are the debates about behavior based robotics, biomimetics, artificial life, and human factors influence. I’m not denying it’s power to enable robots to actually work but what I will be arguing for in this essay is that it’s not enough and it’s definitely not the whole story.

Research in some respects, and to me more recently, is about persuasion. The machine learning perspective is dominant right now. It is powerful, it is explanatory, it is objective, and it gets results. I get it, I understand machine learning as much as I need to be to be dangerous but it is a language and a culture of practice. What I mean by that is that there is an “in”; you have to be able to explain your work using language like “beliefs”, “states”, “transition functions”, etc. These are generic words that allow you to communicate to someone who studies machine learning day-to-day. The machine learning-ist is predominantly interested in datasets and ROC curves. They make their living understanding data and improving on problems that need solutions. Machine learning has been incredibly successful in this regard - ML techniques can dominate your solution.

That being said, I’ve had discussions with ML practicing researchers who fundamentally believe that all you need for intelligent agents is stacks and stacks of markov decision processes, bayes net, neural nets, or … pick your poison. So then why haven’t we just scaled up and created a thinking robot? The truth of the matter is that we are selling our position. This is eventually the goal, but we aren’t ready yet because there is so much we don’t understand.

I heard a legend (real? cautionary? fake?) once about a PhD student in the AI lab who believed in his model of constructionism so much that he implemented his algorithm early in his PhD and let it learn for years. By the end of his dissertation - it could figure out that if it turns its head left, everything goes right and if it turned its head right, everything goes left. I think this is an amazing result, no doubt. Especially for a demonstration implemented so long ago. What I took from it was different: what are you really trying to do? Undirected learning is interesting but learning needs direction and structure before it learns what you want it to learn. 

Most machine learning approaches begins with a dataset. This can represent your sensor data. If you’re learning a map, it may contain laser range data (distances from your sensor to an obstacle) or it may contain image templates and labels (that represent pictures of an apple, say, and the word “apple”), etc etc. You learn a mapping from “sensation” to symbol or “sensation” to a sense of “place” (your nominal position estimate in continuous space). Machine learning is fundamentally about learning. Learning of course isn’t the whole story. I’ve heard arguments that our entire brain is plastic - meaning neurons can be “reprogrammed” to do different things. When you lose a part of your brain in an accident, your brain may learn to compensate differently and you may be able to learn to walk again. Or so the story goes. Learning begins with parameter estimation - you pick a model and then fit your parameters. You are essentially reprogramming your model to fit the data. Then when new data comes in “test phase vs training phase”, you give it an answer based on how your model responds. The strength of learning statistical models is that the model is “plastic” rather than “rigid”. So how is this approach different from the situated approach and biomimetics?

Let’s quickly look at this hypothesis - that all you need to throw at the problem is more neurons, more stacks of neurons… So then the animal with the largest brain on planet earth, the sperm whale, should be able to solve some of the world’s most pressing issues? Why haven’t whales or elephants mounted coordinated attacks against humans who kill them for ivory and manufactured products? Machine learning is an important component of the overall structure of how the brain works but it isn’t the whole story. How the model is laid out matters most. How the different parts of the brain coordinate to produce emergent behavior is the most challenging question facing cognitive science, social psychology, neuroscience, and robotics. For anyone to claim they have an answer, you need to first be skeptical. 

The rest of my essay will be on my particular stance that I prefer: situated cognition. 

Situated Cognition
Let’s try to reprogram your model of AI, intelligent behavior, and robotics and begin again. Erase everything you once knew (if you learned about robotics from a traditional program) and hop inside your own brain for a moment. There is a big wide world out there that you are trying to navigate and adapt to. Let’s begin by looking at vision as a microcosm of how intelligence works. 

Every moment in time your eye is being bombarded with photons that represent the external world. These exposed neurons trigger a chain reaction across your optic nerve, encoding what you see and experience. The eye can be considered one of many gates to your brain. One of the coolest aspects of visual experience is something called ‘visual search’. Visual search refers to the behavior of your eyeball as it saccades from one object of interest to another. Why does it do this? Why doesn’t it just remain still and evaluate all possibilities without making another saccade? Furthermore, if you’ve ever seen the gorilla demonstration, then you know you can even be staring directly at a stimulus and not be computing what is happening directly in front of your eyeball. This phenomena is called ‘selective attention’. Attention is one of the key points of evidence for situated cognition: the idea that we are activity, object, and action oriented creatures. This language is wholly different from that of machine learning theorists and places more emphasis on ‘tuning in to the phenomena’ that the brain is interested in, selectively gating out processing that may be unnecessary for the activity that the agent is trying to accomplish. The scene is no longer a dataset but something to interact with, something to take actions on. Moving attention from one object to another, selectively choosing what to evaluate and when, and choosing what actions are relevant to evaluate. These questions become the most important questions in the situated approach as they are not well understood. Furthermore, what additionally becomes interesting is how these problems are solved by the ML approach. When performing activity recognition for the machine learning approach, selection is implicit in the problem domain. Encoded in the step of “selecting the features” is attention. What should the machine learning algorithm focus on to do the recognition? The expert solves the problem implicitly in the dataset and dataset processing. Machine Learning researchers who focus on this strictly from a statistical viewpoint focus on a topic called “feature selection” or “dimensionality reduction” or “feature extraction”. As a separate and distinct topic, statistical feature selection is an incredibly challenging subject. So let’s go back to biomimetics and the situated approach. 

Joint Attention or ‘Why I do what I do’
Simon Baron Cohen wrote a book called “Mindblindness” in the mid-90s that attempts to pull apart the 
